---
title: "Modelo de predicción de popularidad de películas"
author: "Pablo Perez"
date: "20/11/2020"
output:
  html_document: default
  pdf_document: default
  word_document: default
---
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(warning = FALSE)

```




# Objetivos 

*  Limpieza de un set de datos y análisis de popularidad de películas a partir del siguiente  dataset  https://www.kaggle.com/tmdb/tmdb-movie-metadata

* Obtención de un modelo de predicción que no utilice como predictoras variables relacionadas con la popularidad  de manera tal de emular un sistema de predicción de popularidad de una película __antes de su lanzamiento__. Para ello solo se utilizaran las siguientes variables:
  + Presupuesto (Budget)
  + Idioma original 
  + Actores principales, director, guionista principal, productor ejecutivo, principales compañías de producción.
  + Duración de la película
  + Géneros
  + Mes de lanzamiento

* El script en su totalidad debe correr rápido (< 1hs) en una computadora promedio. 

```{r,  warning=FALSE}
if (!require("pacman")) install.packages("pacman")
library(pacman)
pacman::p_load(ggplot2, plyr, data.table, readr, jsonlite, lubridate, DT, caret, odelr, ISLR, pROC, cowplot, OneR, rlang, caret, RColorBrewer, ggbiplot, GGally, purrr, tidyr, tidymodels, dplyr, DiceKriging, mlrMBO)

require("lightgbm") #probablemente la instalación de lgbm deba hacerse de forma manual 

json_to_df <- function(df, column){
  column_1 <- df[apply(df[,column],1,nchar)>2,]  
  
  list_1 <- lapply(column_1[[column]], fromJSON) 
  values <- data.frame(unlist(lapply(list_1, function(x) paste(x$name,collapse = ",")))) 
  
  final_df <- cbind(column_1$id, column_1$title, values) 
  names(final_df)  <- c("id", "title", column)
  return(final_df)
  
}

setwd("~/MAESTRIA/movies") #directorio de trabajo - CAMBIAR EN CASO DE EJECUTAR EN OTRA COMPUTADORA

#cargo datasets
movies = read_csv("tmdb_5000_movies.csv")
credits = read_csv("tmdb_5000_credits.csv")
    


```

---
```{r, include=FALSE}
#Eliminar este bloque si se ejecuta en otra computadora
load("~/MAESTRIA/movies/todoenviroment.RData")
```

***

# Preprocesamiento

```{r }
#observar datasets
head(credits,10)
head(movies,10)


numericas = c("budget", "popularity",  "vote_average", "vote_count",  "revenue", "runtime" )

ggpairs(select(movies, numericas))


```

```{r,echo=FALSE }
par(mfrow=c(2,3))
for( i in numericas){
    boxplot(movies[,i], main = i)
  
}

```


El pair plot de las variable snuméricas muestra una __alta correlación entre la recaudación, popularidad y cantidad de votos en TMDB__. Además como se observa en los boxplots el dataset posee ruido y un proceso de limpieza de outliers y corección de ceros y NAs puede mejorar la performance de un modelo de predicción.

### Limpieza de Outliers y tratamiento de nulos

```{r}

#corrijo ceros en los datos donde no tiene sentido. 
movies$budget[movies$budget == 0] <- NA
movies$revenue[movies$revenue == 0] <- NA
movies$runtime[movies$runtime == 0] <- NA

#guardo en dataset auxiliar para no sacarlo en el filtrado
df_aux = filter(movies, is.na(budget) |  is.na(revenue) | is.na(runtime) )


#Remuevo outliers (el criterio es arbritrario,utilizando +-3 rango intercuartilico)
movies = na.omit(movies)  %>%
  filter(revenue < quantile(revenue)[4]+3*IQR(revenue)) %>%
  filter(popularity < quantile(popularity)[4]+3*IQR(popularity)) %>%
  filter(vote_count  < quantile(vote_count)[4]+3*IQR(vote_count) ) %>%
  filter(budget < quantile(budget)[4]+3*IQR(budget) ) %>%
  filter(runtime > quantile(runtime)[2]-3*IQR(runtime)  & runtime < quantile(runtime)[4]+3*IQR(runtime)  )
                          
#vuelvo a unir con NA
movies = rbind(movies, df_aux)
  
  
  
```

### Extracción mes del campo de fecha

Lógicamente, el mes es más importante en el estreno de una película que el día. El año no aporta información comparable entre películas. 

```{r}
movies$mes_lanzamiento = month(as.POSIXlt(movies$release_date, format="%Y-%m-%d")) #creo columna con el mes de lanzamiento
numericas = c("budget", "popularity",  "vote_average", "vote_count", "mes_lanzamiento", "revenue", "runtime" )

```



```{r }
par(mfrow=c(3,3))
for( i in numericas){
    boxplot(movies[,i], main = i)
  
}

ggpairs(select(movies, numericas))

```

### Tratamiento de las columnas en formato JSON

Los datos provistos poseen varias __columnas en formato json__ que R interpreta como strings, deben ser extraidos con la libreria jsonlite y posteriormente una selección criterioza para no incrementar drásticamente el tamaño del dataset con variables innecesarias. 



```{r}

# Extracción de dos productoras 
productoras = separate(json_to_df(movies, "production_companies"), production_companies, c("productora_1", "productora_2"), sep = ",")
productoras$movie_id = productoras$id
productoras$id = NULL


#Extraigo campo de directores de la columna crew
directores_df=   plyr::ldply(mapply(cbind, lapply(credits$crew, fromJSON), "movie_id"=credits$movie_id, SIMPLIFY=F), data.frame)

directores_df = directores_df %>% filter( job %in% c("Director", "Executive Producer", "Screenplay")) %>% 
  select(job, name, movie_id) %>% 
  pivot_wider(id_cols = movie_id, names_from = job, values_from = name) 
  
#Me quedo solo con el 1er director, guionista y productor
for(i in 1:nrow(directores_df)){
  
   if(length(directores_df$Director[i][[1]]) > 1){
     directores_df$Director[i][[1]] = directores_df$Director[i][[1]][1]
   }
  
  if(length(directores_df$`Executive Producer`[i][[1]]) > 1){
    directores_df$`Executive Producer`[i][[1]] = directores_df$`Executive Producer`[i][[1]][1]
  }  
    if(length(directores_df$Screenplay[i][[1]]) > 1){
      directores_df$Screenplay[i][[1]] = directores_df$Screenplay[i][[1]][1]
    }  
  }

directores_df$movie_id = as.numeric(directores_df$movie_id)


#Extraigo campo de actor de la columna cast
actores_df = ldply(mapply(cbind, lapply(credits$cast, fromJSON), "movie_id"=credits$movie_id, SIMPLIFY=F), data.frame)
actores_df$movie_id = as.numeric(actores_df$movie_id)   


#limpio
actores_df = actores_df %>% filter(order %in% c(0,1,2)) %>% 
  select(name, order, movie_id) %>%
  pivot_wider(id_cols = movie_id, names_from = order, values_from = name) 

#solo retengo 3 actores para facilitar costo computacional
colnames(actores_df)[2:4] <- c("actor_1", "actor_2", "actor_3")

#Generos
generos = ldply(mapply(cbind, lapply(movies$genres, fromJSON), "movie_id"=movies$id, SIMPLIFY=F), data.frame) %>% 
  mutate(value = 1)  %>%
  spread(name, value,  fill = 0 ) #one Hot Enconding

generos$movie_id = as.numeric(generos$movie_id)  
generos$id = NULL
colnames(generos[22]) = 'Otros'
generos = generos %>% group_by(movie_id)  %>% summarise_all(sum) #agrupamiento 
```

### Combinacion de todos los data.frames y limpieza final

```{r}
#subset de Movies
movies_df = select(movies, budget, original_language, status, mes_lanzamiento, revenue, title, id, popularity, runtime, vote_average, vote_count)
movies_df$movie_id = movies_df$id
movies_df$id = NULL


dataset = list(movies_df, actores_df, directores_df, generos, productoras) %>% reduce(full_join, by = "movie_id") #join de todos

#mas limpieza
dataset = dplyr::rename(dataset, Otros = `<NA>`, titulo = title.x)
dataset = dplyr::filter(dataset, status == "Released") 
dataset =  dplyr::select(dataset, -c("status", "title.y"))

#mas corrección 
dataset$actor_1 = as.factor(as.character(dataset$actor_1))
dataset$actor_2 = as.factor(as.character(dataset$actor_2))
dataset$actor_3 = as.factor(as.character(dataset$actor_3))
dataset$Director = as.factor(as.character(dataset$Director))
dataset$Screenplay = as.factor(as.character(dataset$Screenplay))
dataset$Producer = as.factor(as.character(dataset$`Executive Producer`))
dataset$`Executive Producer` = NULL
dataset$original_language = as.factor(dataset$original_language)


```

***

# Modelo de predicción

### Modelo Lineal Multiple

Un modelo muy simple pero rápido para evaluar importancia de variables. No permite el manejo de variables categóricas con alta cardinalidad como los campos de actores o directores, además la gran cantidad de variables reduce su significatividad estadística. El máximo R^2^ obtenido es de 0.34. 


```{r}

modelo_lineal = lm(popularity ~ budget  + original_language + mes_lanzamiento  +  runtime +  Action     +    Adventure +        Animation     +    Comedy     +       Crime   +          Documentary   +    Drama      +       Family      +      Fantasy      +     Foreign     +      History       +    Horror        +    Music      +       Mystery     +      Romance    +      
 `Science Fiction` +   Thriller      +    `TV Movie`    +      War    +           Western    +       Otros , data = dataset    ) 

#reporto modelo
summary(modelo_lineal)

```

### Modelo de predicción LGBM


__Light Gradient Boosting Machines (LGBM)__ es un algoritmo de creciente popularidad con una velocidad mucho mayor que otros algoritmos de gradient boosting como CatBoost o XGBOOST. A diferencia de otros métodos de partición como Random forest, permite trabajar con valores nulos y variables categóricas no encodeadas, por otra parte, al no ser un método lineal permite trabajar con variables correlacionadas como hay en este set de datos. 



### Partición de los datos en entrenamiento, validación y test

```{r}

#### Separacion en entrenamiento, validación y test

# Partición Train y test, indicando proporción
train_test <- initial_split(dataset, prop = 0.9)
entrenamiento <- training(train_test)
test <- testing(train_test)


# Partición Train y validacion, indicando proporción
train_test <- initial_split(entrenamiento, prop = 0.8)
entrenamiento <- training(train_test)
validacion <- testing(train_test)


campos_buenos = setdiff(  colnames(dataset) ,  c("vote_average","vote_count", "popularity", "titulo", "movie_id", "revenue") )


#dejo los datos en el formato que necesita LightGBM
dBO_train  <-   lgb.Dataset( data  =  data.matrix(select(entrenamiento, all_of(campos_buenos))),
                             label = entrenamiento$popularity,
                             free_raw_data=F)

dBO_test   <-     lgb.Dataset( data  =  data.matrix(select(validacion, all_of(campos_buenos))),
                               label = validacion$popularity,
                               free_raw_data=F)
```

### Búsqueda de hyperparámetros con Optimización Bayesiana

La optimización bayesiana funciona realizando la aproximación del modelo a un función matemática determinada, arroja mejores resultados que un método de random search manteniendo un balance de recursos en comparación con un grid search 

```{r, eval=FALSE}
#en este archivos queda el resultado
kbayesiana  <-  paste0("./bayesiana_MOVIES", ".RDATA" )
kBO_iter    <-  100  #cantidad de iteraciones 

categoricas = c("Director", "Screenplay",  "original_language", "Producer", "productora_1", "productora_2", "actor_1",
                "actor_2", "actor_3")



estimar_lightgbm <- function( x ){
  set.seed( 36761116 )  # para que siempre me de el mismo resultado
  modelo <-  lgb.train(data= dBO_train,
                       objective= "regression",  
                       #eval= fganancia_logistic_lightgbm,  #esta es la fuciona optimizar
                       eval= c("rmse"),
                       valids= list( valid= dBO_test),
                       #metric= "rmse",  
                       boosting = "gbdt",
                       num_iterations=  999999, 
                       early_stopping_rounds= as.integer(50 + 5/x$plearning_rate),
                       learning_rate= x$plearning_rate,
                       #min_data_in_leaf= as.integer(x$pmin_data_in_leaf), 
                       feature_fraction= x$pfeature_fraction,
                       min_gain_to_split=  x$pmin_gain_to_split,
                       num_leaves=  x$pnum_leaves,
                       lambda_l1= x$plambda_l1,
                       lambda_l2= x$plambda_l2,
                       categorical_feature = categoricas,
                       #feature_pre_filter=FALSE,
                       #max_bin= 31,
                       verbosity= -1,
                       verbose= -1
  )
  
  nrounds_optimo <- modelo$best_iter
  pRMSE   <- unlist(modelo$record_evals$valid$rmse$eval)[ nrounds_optimo ] 
  attr(pRMSE ,"extras" ) <- list("pnum_iterations"= modelo$best_iter)  #esta es la forma de devolver un parametro extra
  cat( pRMSE, " " )
  return(pRMSE)
}
#------------------------------------------------------------------------------


configureMlr(show.learner.output = FALSE)
funcion_optimizar <-  estimar_lightgbm 

#configuro la busqueda bayesiana
obj.fun <- makeSingleObjectiveFunction(
  name = "OptimBayesiana",  
  fn   = funcion_optimizar,  
  minimize= TRUE,  #quiero miminizar el error
  par.set = makeParamSet(
    makeIntegerParam("pnum_leaves",       lower=  2L   , upper= 2000L),
    makeNumericParam("pfeature_fraction", lower=  0.10 , upper=    1.0),
    makeNumericParam("pmin_gain_to_split",lower=  0.0  , upper=   50),
    makeNumericParam("plearning_rate",    lower=  0.01 , upper=    0.1),
    makeNumericParam("plambda_l1",        lower=  0.0  , upper=   10),
    #makeNumericParam("pmin_data_in_leaf",  lower=  1, upper=  200 ),
    makeNumericParam("plambda_l2",        lower=  0.0  , upper=  100)
  ),
  has.simple.signature = FALSE,  
  noisy= TRUE
)

ctrl  <-  makeMBOControl( save.on.disk.at.time = 600,  save.file.path = kbayesiana )
ctrl  <-  setMBOControlTermination(ctrl, iters = kBO_iter )
ctrl  <-  setMBOControlInfill(ctrl, crit = makeMBOInfillCritEI())

surr.km  <-  makeLearner("regr.km", predict.type= "se", covtype= "matern3_2", control = list(trace = FALSE))

######################

#Paso valores de la búsqueda bayesiana a hiperparámetros

run  <-  mbo(obj.fun, learner = surr.km, control = ctrl)

```


### Entrenamiento del modelo con los mejores hyperparametros hallados 

```{r modelo train, eval=FALSE }

info_bo  <- as.data.frame(run$opt.path)
setorder( info_bo , y)


categoricas = c("Director", "Screenplay",  "original_language", "Producer", "productora_1", "productora_2", "actor_1",
                "actor_2", "actor_3")

modelo  <- lgb.train( data= dBO_train,
                      obj= "regression",
                      metric = "rmse",
                      boosting = "gbdt",
                      #max_bin= 200,
                      num_iterations=    info_bo$pnum_iterations[1],
                      learning_rate=     info_bo$plearning_rate[1],
                      feature_fraction=  info_bo$pfeature_fraction[1],
                      min_gain_to_split= info_bo$pmin_gain_to_split[1],
                      num_leaves=        info_bo$pnum_leaves[1],
                      lambda_l1=         info_bo$plambda_l1[1],
                      lambda_l2=         info_bo$plambda_l2[1],
                      #min_data_in_leaf = info_bo$pmindata_in_leaf[1],
                      categorical_feature	 = categoricas 
)


#PREDICCION EN VALIDACION  ----------------------------------
prediccion <- predict(modelo, data.matrix(select(validacion, all_of(campos_buenos))))


#Paso resultado a dataframe --------------------------------------------------
resultado  <-   as.data.frame(cbind( "pelicula"= validacion$titulo, "recaudacion" = validacion$revenue,  "real" =  validacion$popularity,  "prediccion" =prediccion) )

#corección de formato de datos (posible bug de R)
resultado$recaudacion = as.numeric(resultado$recaudacion)
resultado$real = as.numeric(resultado$real)
resultado$prediccion = as.numeric(resultado$prediccion)

melted = tidyr::pivot_longer(resultado, cols = 3:4, names_to ="tipo") %>% arrange(desc(value)) #pivot de la tabla
melted$value = as.numeric(melted$value ) #corección de formato de datos (posible bug de R)
```


### Graficos de performance en set de validacion  

El modelo muestra un buen ajuste de los datos predichos en el set de validación, con un valor mínimo de RMSE cercano a 14. Si los valores de popularidad predichos fuesen muy distintos, no debería haber ninguna correlación entre uno y otro y las curvas de distribución no deberían solaparse. 



```{r}

ggplot(info_bo, aes(x= exec.time, y = y)) +
  geom_line()  +
  geom_smooth(method = lm) + 
  labs(title ="Evolucion del RMSE con las sucesivas iteraciones", y = "RMSE: error medio cuadrático", x= " ")



### GRAFICOS -----------------------------------------------------------------------------------------------------
ggplot(melted, aes(x=pelicula, y= value, color = tipo))+
  geom_point(alpha=0.5) +
  labs(title = "Popularidad de las peliculas", y="popularidad", x = "Película") +
  theme(axis.text.x = element_blank(), axis.text.y = element_blank()) 



ggplot(melted, aes(value, fill =tipo)) + 
  geom_density(kernel = "gaussian", alpha = 0.5, color = NA) + 
  labs(title = "Popularidad de las peliculas", y="frecuencia", x = "popularidad") +
  scale_x_continuous(trans = "sqrt")


ggplot(resultado, aes(real, prediccion, size=recaudacion)) + 
  labs(title = paste0("Predicción vs. valor real. r = ", cor(resultado$prediccion, resultado$real)), y="Predicción del modelo", x = "Popularidad real", legend ="Recaudación") +
   geom_point(alpha = 0.6, color= "limegreen")

```


### Evaluación de dataset de test

Dado que la optimización bayesiana determino los hyperparametros óptimos realizando predicciones sobre el dataset de validación,  observar solamente la performance del modelo sobre el mismo dataset de validación  podría llevar a una sobreestimación del modelo ya que se ignora la posibilidad de __overfitting__ .

La predicción sobre el dataset reservado de test cuyos datos no han sido observados durante el entrenamiento permite un juicio con menor sesgo sobre el modelo realizado, no obstante no se observa una diferencia significativa en la calidad del modelo. 


```{r, eval = FALSE}


#PREDICCION EN TEST  ----------------------------------
prediccion_test <- predict(modelo, data.matrix(select(test, all_of(campos_buenos))))


#Paso resultado a dataframe --------------------------------------------------
resultado_test  <-   as.data.frame(cbind( "pelicula"= test$titulo, "recaudacion" = test$revenue,  "real" =  test$popularity,  "prediccion" =prediccion_test) )

#corección de formato de datos (posible bug de R)
resultado_test$recaudacion = as.numeric(resultado_test$recaudacion)
resultado_test$real = as.numeric(resultado_test$real)
resultado_test$prediccion = as.numeric(resultado_test$prediccion)

melted = tidyr::pivot_longer(resultado_test, cols = 3:4, names_to ="tipo") %>% arrange(desc(value)) #pivot de la tabla
melted$value = as.numeric(melted$value ) #corección de formato de datos (posible bug de R)

```

```{r}

### GRAFICOS -----------------------------------------------------------------------------------------------------
ggplot(melted, aes(x=pelicula, y= value, color = tipo))+
  geom_point(alpha=0.5) +
  labs(title = "Popularidad de las peliculas", y="popularidad", x = "Película") +
  theme(axis.text.x = element_blank(), axis.text.y = element_blank()) 



ggplot(melted, aes(value, fill =tipo)) + 
  geom_density(kernel = "gaussian", alpha = 0.5, color = NA) + 
  labs(title = "Popularidad de las peliculas", y="frecuencia", x = "popularidad") +
  scale_x_continuous(trans = "sqrt")


ggplot(resultado_test, aes(real, prediccion, size=recaudacion)) + 
  labs(title = paste0("Predicción vs. valor real. r = ", cor(resultado_test$prediccion, resultado_test$real)), y="Predicción del modelo", x = "Popularidad real", legend ="Recaudación") +
   geom_point(alpha = 0.6, color= "limegreen")




```
***

# Conclusiones 

* Las variables que más se correlación con la popularidad de una película son la cantidad de votos y la recaudanción, no obstante, estas son variables no independientes de la popularidad y por lo tanto no pueden ser usadas para predecirla a priori de su lanzamiento.  Las variable de presupuesto tiene una correlación moderada (cercana a 0.5). 

* Se puede realizar un modelo lineal múltiple parcialmente signifivativo pero sin un resultado óptimo (R^2^ = 0.34). No permite la introducción de variables categóricas con alta cardinalidad como actores, directores o compañías. 

* El modelo lgbm realizado arroja una predicción correlacionada con la popularidad real de la película solamente con datos previos a su lanzamiento. Sin embargo, se trata de un modelo perfectible que podría mejorar su performance en detrimento del tiempo de ejecución mediante:
    + Optimización Bayesiana prolongada o grid search de hyperparametros
    + Incremento del volumen de datos mediante la __API de TMDB__. 
    + Utilización de k-fold cross validation en lugar de una partición simple. 
    + Utilizar más variables cateogóricas, por ejemplo todo el elenco de la película. 
    + Combinación con datos externos provenientes de redes sociales (Búsqueda en Google de una película o ranking de actores en IMDB, premios de los directores, etc. ) 
    + La aplicación de técnicas de minería de texto como __association rules__   permitiría el análisis de datos no explotados como el resumen de la película. 
    + __feature engeneering__ : corrección de presupuesto en función del año. Cruce de datos de fecha de lanzamiento con "fechas de estrenos" como cercanía a Navidad o vacaciones. 
    + Otro algoritmo de gradient boosting como __XGBOOST__
    



 



